{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include path to our library\n",
    "cwd = os.getcwd()\n",
    "dir_path = os.path.dirname(os.path.realpath(cwd))\n",
    "sys.path.append(dir_path)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path\n",
    "%cd $dir_path\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "from core.data.data_loader import *\n",
    "from core.models.lstm import ModelLSTM, ModelLSTMParalel, ModelLSTMCuDnnParalel\n",
    "from core.models.cnn import ModelCNN\n",
    "from core.models.mlp import ModelMLP\n",
    "\n",
    "from core.utils.metrics import *\n",
    "from core.utils.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading Configurartion ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some configurations configurations of model and others\n",
    "configs = json.load(open('config_lstm.json', 'r'))\n",
    "output_path = configs['paths']['save_dir']\n",
    "output_logs = configs['paths']['log_dir']\n",
    "\n",
    "if os.path.isdir(output_path) == False:\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "if os.path.isdir(output_logs) == False:\n",
    "    os.mkdir(output_logs)        \n",
    "\n",
    "time_steps =  configs['model']['layers'][0]['input_timesteps']  # the number of points or hits\n",
    "num_features = configs['model']['layers'][0]['input_features']  # the number of features of each hits\n",
    "\n",
    "split = configs['data']['train_split']  # the number of features of each hits\n",
    "cylindrical = configs['data']['cylindrical']  # set to polar or cartesian coordenates\n",
    "normalise = configs['data']['normalise'] \n",
    "num_hits = configs['data']['num_hits']\n",
    "print('OK reading of json file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading path of data\n",
    "path = configs['data']['filename']\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(path, split, cylindrical, num_hits, KindNormalization.Zscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data.get_training_data(n_hit_in=time_steps, n_hit_out=1,\n",
    "                                 n_features=num_features, normalise=True)\n",
    "#dataset = dataset.iloc[0:2640,0:]/   b\n",
    "#dataset = dataset.iloc[0:31600,0:]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "X_train.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data     \n",
    "time_steps =  configs['model']['layers'][0]['input_timesteps']  # the number of points or hits\n",
    "num_features = configs['model']['layers'][0]['input_features']  # the number of features of each hits\n",
    "split = configs['data']['train_split']  # the number of features of each hits\n",
    "cylindrical = configs['data']['cylindrical']  # set to polar or cartesian coordenates\n",
    "normalise = configs['data']['normalise'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is empty data?\n",
    "print(X_train.isnull().values.any())\n",
    "#print(X_test.isnull().values.any())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.reshape3d(X_train, time_steps, num_features)\n",
    "\n",
    "print('[Data] shape X_train ', X_train.shape)\n",
    "print('[Data] shape y_train ', y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manage_models(config):\n",
    "    \n",
    "    type_model = config['model']['name']\n",
    "    model = None\n",
    "\n",
    "    if type_model == 'lstm': #simple LSTM\n",
    "        model = ModelLSTM(config)\n",
    "    elif type_model == 'lstm-paralel':\n",
    "        model = ModelLSTMParalel(config)\n",
    "    elif type_model == 'cnn':\n",
    "        model = ModelCNN(config)\n",
    "    elif type_model == 'mlp':\n",
    "        model = ModelMLP(config)        \n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# geramos o modelo\n",
    "#configs = json.load(open('config_test.json', 'r'))\n",
    "model = manage_models(configs)\n",
    "\n",
    "if model is None:\n",
    "    print('Please instance model')\n",
    "\n",
    "loadModel = configs['training']['load_model']\n",
    "#loadModel = False\n",
    "#loadModel = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.utils.metrics import *\n",
    "\n",
    "# in-memory training\n",
    "if loadModel == False:\n",
    "    model.build_model()\n",
    "    # in-memory training\n",
    "    history = model.train(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        epochs = configs['training']['epochs'],\n",
    "        batch_size = configs['training']['batch_size']\n",
    "    )\n",
    "\n",
    "    evaluate_training(history, output_path)\n",
    "\n",
    "elif loadModel == True:       \n",
    "    if not model.load_model():\n",
    "        print ('[Error] please change the config file : load_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate The model (just training)##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model\n",
    "from core.utils.metrics import *\n",
    "#evaluate_training(history,output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Prediction and Nearest ##\n",
    "We concatenate features to predict one hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "import numpy as np\n",
    "from core.utils.metrics import *\n",
    "from core.utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divimos \n",
    "X_test, y_test = data.get_testing_data(n_hit_in=time_steps, n_hit_out=1,\n",
    "                                 n_features=num_features, normalise=True)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "X_test.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Prediction ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ = data.reshape3d(X_test, time_steps, num_features)\n",
    "y_tes_ = data.reshape3d(y_test, 6, num_features)\n",
    "\n",
    "pred_full = model.predict_full_sequences(X_test_, y_tes_, 6)\n",
    "print('finished prediction ...')\n",
    "\n",
    "predicted = convert_vector_to_matrix(pred_full, 3, 6)\n",
    "predicted = to_frame(predicted)\n",
    "predicted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Nearest ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertimos a matriz do test em um vetor \n",
    "#y_test_ = convert_matrix_to_vec(y_test, 3)\n",
    "#y_test_ = np.array(y_test_)\n",
    "\n",
    "pred_full_res, correct = model.predict_full_sequences_nearest(X_test_, y_test, 6)\n",
    "print('finished prediction nearest...')\n",
    "\n",
    "predicted_nearest = convert_vector_to_matrix(pred_full_res, 3, 6)\n",
    "predicted_nearest = to_frame(predicted_nearest)\n",
    "predicted_nearest.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vetor de contagens\n",
    "total = X_test.shape[0]\n",
    "\n",
    "print(correct)\n",
    "\n",
    "#taxa_acertos = [(correct*100)/total for x in range(0, len(correct))]\n",
    "print((correct*100)/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for Normal Prediction ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metricas sem nearest\n",
    "result = calc_score(data.reshape2d(y_test, 1),\n",
    "                    data.reshape2d(predicted, 1), report=False)\n",
    "print(result)\n",
    "r2, rmse, rmses = evaluate_forecast_seq(y_test, predicted)\n",
    "summarize_scores(r2, rmse, rmses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for  Nearest Prediction ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metricas para nearest\n",
    "result = calc_score(data.reshape2d(y_test, 1),\n",
    "                    data.reshape2d(predicted_nearest, 1), report=False)\n",
    "print(result)\n",
    "r2, rmse, rmses = evaluate_forecast_seq(y_test, predicted_nearest)\n",
    "summarize_scores(r2, rmse, rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Millimeters ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalise:\n",
    "    print('[Data] Inverse Transforming ...')\n",
    "    y_test_orig = data.inverse_transform_y(y_test)\n",
    "    y_predicted_orig = data.inverse_transform_y(predicted)\n",
    "    y_predicted_orig_nearest = data.inverse_transform_y(predicted_nearest)\n",
    "    \n",
    "else:\n",
    "    y_test_orig = y_test\n",
    "    y_predicted_orig = predicted\n",
    "    y_predicted_orig_nearest = predicted_nearest\n",
    "\n",
    "\n",
    "y_test_orig = pd.DataFrame(y_test_orig)\n",
    "y_predicted_orig = pd.DataFrame(y_predicted_orig)\n",
    "y_predicted_orig_nearest = pd.DataFrame(y_predicted_orig_nearest)\n",
    "\n",
    "print('[Data] shape y_predicted_orig ', y_predicted_orig.shape)    \n",
    "print('[Data] shape y_test_orig ', y_test_orig.shape)\n",
    "\n",
    "result = calc_score(data.reshape2d(y_test_orig, 1),\n",
    "                    data.reshape2d(y_predicted_orig_nearest, 1), report=False)\n",
    "print(result)\n",
    "r2, rmse, rmses = evaluate_forecast_seq(y_test_orig, y_predicted_orig_nearest)\n",
    "summarize_scores(r2, rmse, rmses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for Visualization ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true, y_true = data.get_testing_data(n_hit_in=time_steps, n_hit_out=1,\n",
    "                                 n_features=num_features, normalise=False)\n",
    "#x_true = X_test\n",
    "#y_true = y_test\n",
    "print(x_true.shape)\n",
    "print(y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join both dataset must be equal to X_test\n",
    "data_test = np.concatenate([x_true , y_true], axis = 1)\n",
    "data_test = pd.DataFrame(data_test)\n",
    "print('Shape ', data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be equal\n",
    "#data_test.values == X_test_new.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join both dataset should be equal to X_test but not equal\n",
    "data_pred = np.concatenate([x_true , y_predicted_orig], axis = 1 )\n",
    "data_pred = pd.DataFrame(data_pred)\n",
    "print('Shape ', data_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join both dataset should be equal to X_test but not equal\n",
    "data_pred_nearest = np.concatenate([x_true , y_predicted_orig_nearest], axis = 1 )\n",
    "data_pred_nearest = pd.DataFrame(data_pred_nearest)\n",
    "print('Shape ', data_pred_nearest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should not be equal\n",
    "#data_pred.values == X_test_new.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cylindrical:\n",
    "\n",
    "    y_test_orig.to_csv(os.path.join(output_path, 'y_true_%s_cylin_nearest.csv' % configs['model']['name']),\n",
    "                header=False, index=False)\n",
    "\n",
    "    y_predicted_orig.to_csv(os.path.join(output_path, 'y_pred_%s_cylin_nearest.csv' % configs['model']['name']),\n",
    "                header=False, index=False)\n",
    "\n",
    "    x_true.to_csv(os.path.join(output_path, 'x_true_%s_cylin_nearest.csv' % configs['model']['name']),\n",
    "                header=False, index=False)\n",
    "else:\n",
    "    \n",
    "    y_test_orig.to_csv(os.path.join(output_path, 'y_true_%s_xyz_nearest.csv' % configs['model']['name']),\n",
    "                header=False, index=False)\n",
    "    y_predicted_orig.to_csv(os.path.join(output_path, 'y_pred_%s_xyz_nearest.csv' % configs['model']['name']),\n",
    "                header=False, index=False)\n",
    "\n",
    "    x_true.to_csv(os.path.join(output_path, 'x_true_%s_xyz_nearest.csv' % configs['model']['name']),\n",
    "                header=False, index=False)\n",
    "\n",
    "print('[Output] Results saved at %', output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados originais\n",
    "N_tracks = 50\n",
    "path_html = ''\n",
    "name = configs['model']['name']\n",
    "\n",
    "if cylindrical:\n",
    "    path_html=os.path.join(output_path, 'track-original-%s_cylin_nearest.html' % name)\n",
    "else:\n",
    "    path_html=os.path.join(output_path, 'track-original-%s_xyz_nearest.html' % name)\n",
    "    \n",
    "fig = track_plot_xyz([data_test], n_hits = 10, cylindrical = cylindrical, n_tracks = 50, \n",
    "               path=path_html, title='Track Original #10 Hit - Model %s' % name.upper())\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted data\n",
    "N_tracks = 30\n",
    "path_html = ''\n",
    "name = configs['model']['name']\n",
    "\n",
    "if cylindrical:\n",
    "    path_html=os.path.join(output_path, 'track-predicted-%s_cylin_nearest.html' % name)\n",
    "else:\n",
    "    path_html=os.path.join(output_path, 'track-predicted-%s_xyz_nearest.html' % name)\n",
    "    \n",
    "fig = track_plot_xyz([data_test, data_pred], n_hits = 10, cylindrical = cylindrical, n_tracks = N_tracks, \n",
    "               path=path_html, title='Track Prediction #10 Hit - Model %s (Nearest hits)' % name.upper())\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted data\n",
    "N_tracks = 3\n",
    "path_html = ''\n",
    "name = configs['model']['name']\n",
    "\n",
    "if cylindrical:\n",
    "    path_html=os.path.join(output_path, 'track-predicted-%s_cylin_nearest.html' % name)\n",
    "else:\n",
    "    path_html=os.path.join(output_path, 'track-predicted-%s_xyz_nearest.html' % name)\n",
    "\n",
    "data_test.name = 'real' \n",
    "data_pred.name = 'predito'\n",
    "data_pred_nearest.name = 'nearest'\n",
    "fig = track_plot_xyz([data_test, data_pred, data_pred_nearest], n_hits = 10, cylindrical = cylindrical, n_tracks = N_tracks, \n",
    "               path=path_html, title='Track Prediction #10 Hit - Model %s (Nearest hits)' % name.upper(), auto_open=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
