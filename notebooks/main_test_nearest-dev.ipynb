{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include path to our library\n",
    "cwd = os.getcwd()\n",
    "dir_path = os.path.dirname(os.path.realpath(cwd))\n",
    "sys.path.append(dir_path)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path\n",
    "%cd $dir_path\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "from core.data.data_loader import *\n",
    "from core.models.lstm import ModelLSTM, ModelLSTMParalel, ModelLSTMCuDnnParalel\n",
    "from core.models.cnn import ModelCNN\n",
    "from core.models.mlp import ModelMLP\n",
    "from core.models.base import BagOfHits\n",
    "\n",
    "from core.utils.metrics import *\n",
    "from core.utils.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading Configurartion ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some configurations configurations of model and others\n",
    "configs = json.load(open('config_lstm.json', 'r'))\n",
    "output_path = configs['paths']['save_dir']\n",
    "output_logs = configs['paths']['log_dir']\n",
    "\n",
    "data_file = configs['data']['filename']\n",
    "\n",
    "#create a encryp name for dataset\n",
    "path_to, filename = os.path.split(data_file)\n",
    "\n",
    "orig_ds_name = filename\n",
    "\n",
    "encryp_ds_name = get_unique_name(orig_ds_name)\n",
    "decryp_ds_name = get_decryp_name(encryp_ds_name)\n",
    "\n",
    "output_encry = os.path.join(output_path, encryp_ds_name)  \n",
    "    \n",
    "if os.path.isdir(output_path) == False:\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "if os.path.isdir(output_encry) == False: \n",
    "    os.mkdir(output_encry)\n",
    "        \n",
    "if os.path.isdir(output_logs) == False:\n",
    "    os.mkdir(output_logs)        \n",
    "\n",
    "time_steps =  configs['model']['layers'][0]['input_timesteps']  # the number of points or hits\n",
    "num_features = configs['model']['layers'][0]['input_features']  # the number of features of each hits\n",
    "split_data = configs['data']['train_split']  # the number of features of each hits\n",
    "cylindrical = configs['data']['cylindrical']  # set to polar or cartesian coordenates\n",
    "#cylindrical = False\n",
    "normalise = configs['data']['normalise'] \n",
    "num_hits = configs['data']['num_hits']\n",
    "type_pred = configs['testing']['type_prediction']\n",
    "tolerance = configs['testing']['tolerance']\n",
    "\n",
    "    \n",
    "print('OK reading of json file')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading path of data\n",
    "path = configs['data']['filename']\n",
    "print(path)\n",
    "print(output_encry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(path, split_data, cylindrical, num_hits, KindNormalization.Zscore)\n",
    "# divimos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data_train.iloc[0:12, 0:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data.get_training_data(n_hit_in=time_steps, n_hit_out=1,\n",
    "                                 n_features=num_features, normalise=True)\n",
    "#dataset = dataset.iloc[0:2640,0:]/   b\n",
    "#dataset = dataset.iloc[0:31600,0:]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "X_train.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manage_models(config):\n",
    "    \n",
    "    type_model = config['model']['name']\n",
    "    model = None\n",
    "\n",
    "    if type_model == 'lstm': #simple LSTM\n",
    "        model = ModelLSTM(config)\n",
    "    elif type_model == 'lstm-paralel':\n",
    "        model = ModelLSTMParalel(config)\n",
    "    elif type_model == 'cnn':\n",
    "        model = ModelCNN(config)\n",
    "    elif type_model == 'mlp':\n",
    "        model = ModelMLP(config)        \n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# geramos o modelo\n",
    "#configs = json.load(open('config_test.json', 'r'))\n",
    "model = manage_models(configs)\n",
    "\n",
    "if model is None:\n",
    "    print('Please instance model')\n",
    "\n",
    "loadModel = configs['training']['load_model']\n",
    "loadModel = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.utils.metrics import *\n",
    "\n",
    "# in-memory training\n",
    "if loadModel == False:\n",
    "    model.build_model()\n",
    "    # in-memory training\n",
    "    history = model.train(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        epochs = configs['training']['epochs'],\n",
    "        batch_size = configs['training']['batch_size']\n",
    "    )\n",
    "\n",
    "    evaluate_training(history, output_path)\n",
    "\n",
    "elif loadModel == True:       \n",
    "    if not model.load_model():\n",
    "        print ('[Error] please change the config file : load_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Prediction and Nearest ##\n",
    "We concatenate features to predict one hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "import numpy as np\n",
    "from core.utils.metrics import *\n",
    "from core.utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not normalized \n",
    "x_scaler, y_scaler = data.load_scale_param(output_encry)\n",
    "\n",
    "normalise_testing = configs['testing']['normalise']\n",
    "\n",
    "X_test, y_test = data.get_testing_data(n_hit_in=time_steps, n_hit_out=1,\n",
    "                                       n_features=num_features, normalise=normalise_testing,\n",
    "                                       xscaler=x_scaler, yscaler=y_scaler)\n",
    "\n",
    "#X_test, y_test = data.get_testing_data(n_hit_in=time_steps, n_hit_out=1,\n",
    "#                                       n_features=num_features, normalise=False,\n",
    "#                                       xscaler=None, yscaler=None)\n",
    "\n",
    "\n",
    "#X_test = X_test.iloc[0:1000,]\n",
    "#y_test = y_test[0:1000]\n",
    "\n",
    "#orig\n",
    "#data.data_test.head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "X_test.head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Prediction ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ = data.reshape3d(X_test, time_steps, num_features)\n",
    "y_test_ = data.reshape3d(y_test, 6, num_features)\n",
    "\n",
    "print(X_test_.shape)\n",
    "print(y_test_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_full_sequences(x_test, data, num_hits=6, normalise=False):\n",
    "    '''\n",
    "        x_test: input data\n",
    "        normalise: say input data must be scaled \n",
    "    '''\n",
    "    timer = Timer()\n",
    "    timer.start() \n",
    "    print('[Model] Predicting Sequences Started')\n",
    "\n",
    "    total = len(x_test)\n",
    "\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    pred_sequences = []\n",
    "\n",
    "    for j in range(total):       \n",
    "        curr_frame = x_test[j]\n",
    "        predicted = []\n",
    "        for i in range(num_hits):\n",
    "            if normalise:\n",
    "                curr_frame = data.x_scaler.transform(np.reshape(curr_frame,(1,12)))\n",
    "                curr_frame_orig = data.inverse_transform_x(pd.DataFrame(curr_frame).values.flatten())\n",
    "                curr_frame_orig = np.reshape(curr_frame_orig, (4,3))\n",
    "                curr_frame = np.reshape(curr_frame, (4,3))\n",
    "            else:\n",
    "                curr_frame = curr_frame\n",
    "                curr_frame_orig = curr_frame\n",
    "                            \n",
    "            pred = model.model.predict(curr_frame[np.newaxis,:,:])                         \n",
    "            \n",
    "            pred = np.reshape(pred, (1, 3))\n",
    "            if normalise:\n",
    "                pred = data.inverse_transform_y(pred)\n",
    "            else:\n",
    "                pred = pred\n",
    "                \n",
    "            pred = np.reshape(pred, (1, 3))\n",
    "            \n",
    "            predicted.append(pred)\n",
    "            curr_frame = curr_frame_orig[1:]\n",
    "            # inserta um  valor np.insert(array, index, value, axes)\n",
    "            curr_frame = np.insert(curr_frame, [3], predicted[-1], axis=0)\n",
    "            #print(curr_frame, predicted[-1])\n",
    "\n",
    "        pred_sequences.append(predicted)\n",
    "\n",
    "    print('[Model] Prediction Finished.')\n",
    "    timer.stop()\n",
    "\n",
    "    return pred_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise = True say the input must be normalised\n",
    "pred_full = predict_full_sequences(X_test_, data, num_hits=6, normalise=True)\n",
    "print('finished prediction ...')\n",
    "\n",
    "predicted = convert_vector_to_matrix(pred_full, 3, 6)\n",
    "predicted = to_frame(predicted)\n",
    "predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# original data y_true\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Nearest ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag_of_hits = None\n",
    "from enum import Enum\n",
    "\n",
    "def predict_full_sequences_nearest1(x_test, y_test, num_hits=6, num_features=3, normalise=False):\n",
    "    \n",
    "    timer = Timer()\n",
    "    timer.start()       \n",
    "\n",
    "    print('[Model] Predicting Sequences with Nearest Started')\n",
    "\n",
    "    total = len(x_test)\n",
    "\n",
    "    pred_sequences = []\n",
    "\n",
    "    decimals = 2\n",
    "    y_true = None\n",
    "    \n",
    "    #if normalise:\n",
    "    # covert to original values\n",
    "    y_true = data.inverse_transform_test_y(y_test)\n",
    "        \n",
    "    #y_true = y_true.round(decimals)\n",
    "    \n",
    "    #x_test must be in scaled form\n",
    "\n",
    "    global bag_of_hits \n",
    "    bag_of_hits = np.array(convert_matrix_to_vec(y_true, num_features))\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    count_correct = np.zeros(num_hits)\n",
    "\n",
    "    for j in range(total):\n",
    "        curr_frame = x_test[j]\n",
    "        curr_track = y_true[j]\n",
    "        \n",
    "        predicted = []\n",
    "        begin = 0\n",
    "        #print('track :', curr_track)\n",
    "        for i in range(num_hits):\n",
    "            end = begin+num_features\n",
    "            curr_hit_orig = curr_track[begin:end]\n",
    "            begin = end\n",
    "            \n",
    "            #print('curr_frame:\\n', curr_frame)\n",
    "            # input must be scaled curr_frame\n",
    "            y_pred = model.model.predict(curr_frame[np.newaxis,:,:])\n",
    "\n",
    "            #print('pred:', y_pred)\n",
    "            y_pred = np.reshape(y_pred, (1, 3))\n",
    "            y_pred_orig = data.inverse_transform_y(y_pred)\n",
    "            #y_pred_orig = np.round(y_pred_orig, decimals)\n",
    "            #print('pred:', y_pred)\n",
    "            \n",
    "            print('BoH: %s, %s'%(len(bag_of_hits), bag_of_hits))\n",
    "\n",
    "            near_pred_orig, idx = model.nearest_hit(y_pred_orig, bag_of_hits, silent=True)\n",
    "            \n",
    "            #print('inv pred:', y_pred_orig)\n",
    "            #print('nearest:', near_pred_orig)\n",
    "            #print('current:', curr_hit_orig)\n",
    "\n",
    "            d1 = calculate_distances_vec(curr_hit_orig, y_pred_orig[0])\n",
    "            d2 = calculate_distances_vec(curr_hit_orig, near_pred_orig)\n",
    "            \n",
    "            #print('dist pred: %s  dist near : %s ' % (d1, d2))\n",
    "            \n",
    "            #bag_of_hits = np.delete(bag_of_hits, idx, 0)\n",
    "            \n",
    "            #if np.logical_and(curr_hit, near_pred).all():\n",
    "            #if np.array_equal(curr_hit, near_pred):\n",
    "                          \n",
    "            if d1 <= d2:\n",
    "                # original coordinates\n",
    "                if np.isclose(curr_hit_orig, y_pred_orig, atol=0.09).all():    \n",
    "                    count_correct[i]=+1\n",
    "                    \n",
    "                predicted.append(y_pred)\n",
    "            else:\n",
    "                # original coordinates\n",
    "                if np.isclose(curr_hit_orig, near_pred_orig, atol=0.09).all():    \n",
    "                    count_correct[i]=+1\n",
    "                               \n",
    "                near_pred = data.y_scaler.transform(np.reshape(near_pred_orig, (1, 3)))\n",
    "                #print('current inv:', near_pred)\n",
    "                predicted.append(near_pred)\n",
    "                      \n",
    "            curr_frame = curr_frame[1:]\n",
    "            # inserta um  valor np.insert(array, index, value, axes)\n",
    "            curr_frame = np.insert(curr_frame, [3], predicted[-1], axis=0)\n",
    "        \n",
    "        pred_sequences.append(predicted)\n",
    "        if j == 2: break\n",
    "    print('[Model] Prediction Finished.')\n",
    "    timer.stop()\n",
    "\n",
    "    return pred_sequences, count_correct\n",
    "\n",
    "def nearest_hit(hit, hits,\n",
    "                    silent = True,\n",
    "                    metric = 'euclidean'):\n",
    "\n",
    "    if silent is False:\n",
    "        timer = Timer()\n",
    "        timer.start()\n",
    "\n",
    "    dist = distance.cdist(hits, hit, metric)\n",
    "\n",
    "    # get the index of minimum distance\n",
    "    target_hit_index = np.argmin(dist)\n",
    "\n",
    "    if silent is False:    \n",
    "        print(\"--- N_hits: %s\" % len(hits))\n",
    "        print(\"--- Hit index: %s\" % target_hit_index)\n",
    "        print(\"--- \" + str(metric) + \" distance: \" + str(dist[target_hit_index]))\n",
    "        print(\"--- time: %s seconds\" % timer.stop())\n",
    "\n",
    "    # get hits coordinates \n",
    "    real_hit = hits[target_hit_index, :]\n",
    "    real_hit = np.array(real_hit)\n",
    "\n",
    "    # removing the hit from bag\n",
    "    #hits = np.delete(hits, target_hit_index, 0)\n",
    "\n",
    "    if dist_hit is False:\n",
    "        return real_hit, target_hit_index\n",
    "    else:\n",
    "        return real_hit, target_hit_index, np.min(dist)\n",
    "\n",
    "def mat_rhoetaphi_to_xyz(mat, n_hits = 5):\n",
    "    pivot_tmp = 0\n",
    "    for i in range(n_hits):\n",
    "        pivot_tmp = i * 3\n",
    "        rho = mat[pivot_tmp + 0]\n",
    "        eta = mat[pivot_tmp + 1]\n",
    "        phi = mat[pivot_tmp + 2]\n",
    "        if (rho != 0 and eta != 0 and phi != 0):\n",
    "            x, y, z = convert_rhoetaphi_to_xyz(rho, eta, phi)\n",
    "            mat[pivot_tmp + 0] = x\n",
    "            mat[pivot_tmp + 1] = y\n",
    "            mat[pivot_tmp + 2] = z\n",
    "    return mat\n",
    "\n",
    "class BagOfHits(Enum):\n",
    "    All=1,\n",
    "    Track=2,\n",
    "    Layer=3\n",
    "    \n",
    "def predict_full_sequences_nearest2(x_test, y_test, bag_of_hits, y_test_aux=None, num_hits=6, num_features=3,\n",
    "                                    normalise=False, cylindrical=False, verbose=False, tol=0.01):\n",
    "    \n",
    "    '''\n",
    "        This function shift the window by 1 new prediction each time, re-run predictions on new window\n",
    "        parameters:\n",
    "        x_test : X test data normaly not scaled (4 hits)\n",
    "        y_test : y test data, normaly not scaled (6 hits)\n",
    "        num_hits : how many hits by y_test\n",
    "        normalise : it param says the input data must be scaled or not\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    timer = Timer()\n",
    "    timer.start()\n",
    "\n",
    "    print('[Model] Predicting Sequences with Nearest Started')\n",
    "\n",
    "    total = len(x_test)\n",
    "\n",
    "    pred_sequences = []\n",
    "    pred_sequences_orig = []\n",
    "    \n",
    "    decimals = 2\n",
    "   \n",
    "    # covert to original values\n",
    "    #y_true = data.inverse_transform_test_y(y_test)\n",
    "    #y_true = y_true.round(decimals)\n",
    "    \n",
    "    #change the dataset by cartesian coordinates\n",
    "    if cylindrical:\n",
    "        y_test = y_test_aux\n",
    "    else:\n",
    "        y_test = y_test\n",
    "        \n",
    "    # bag_of_hits  \n",
    "    bag_of_hits_all = np.array(convert_matrix_to_vec(y_test, num_features))\n",
    "\n",
    "    count_correct = np.zeros(num_hits)\n",
    "    begin_idx, end_idx = 0, 0\n",
    "    num_boh = 6\n",
    "    \n",
    "    for j in range(total):\n",
    "        curr_frame = x_test[j]\n",
    "        # bag_of_hit by track\n",
    "        curr_track = np.array(y_test.iloc[j,0:]).reshape(num_hits, num_features)\n",
    "        \n",
    "        if verbose:\n",
    "            print('curr_track %s , %s:' % (j , curr_track))\n",
    "\n",
    "        predicted = []\n",
    "        predicted_orig = []\n",
    "        begin = 0\n",
    "        for i in range(num_hits):\n",
    "            # bag_of_hit by layer\n",
    "            end = begin+num_features\n",
    "            curr_layer = np.array(y_test.iloc[0:,begin:end]).reshape(total, num_features)\n",
    "            curr_hit = curr_track[i]\n",
    "            begin = end\n",
    "            \n",
    "            if verbose:\n",
    "                # primeira esta em originais\n",
    "                print('input:\\n', curr_frame)\n",
    "            \n",
    "            if normalise:\n",
    "                curr_frame = data.x_scaler.transform(np.reshape(curr_frame,(1,12)))\n",
    "                curr_frame_orig = data.inverse_transform_x(pd.DataFrame(curr_frame).values.flatten())\n",
    "                curr_frame_orig = np.reshape(curr_frame_orig, (4,3))\n",
    "                curr_frame = np.reshape(curr_frame, (4,3))\n",
    "            else:\n",
    "                curr_frame = curr_frame\n",
    "                curr_frame_orig = curr_frame\n",
    "                \n",
    "            if verbose:\n",
    "                print('input:\\n', curr_frame)\n",
    "                #print('input orig:\\n', curr_frame_orig)\n",
    "            \n",
    "            #print('input inv :\\n', curr_frame_inv.reshape(4,3))\n",
    "            #print('newaxis ', curr_frame[np.newaxis,:,:])\n",
    "            # input must be scaled curr_frame\n",
    "            y_pred = model.model.predict(curr_frame[np.newaxis,:,:])\n",
    "\n",
    "            \n",
    "            y_pred = np.reshape(y_pred, (1, 3))\n",
    "            if normalise:\n",
    "                y_pred_orig = data.inverse_transform_y(y_pred)\n",
    "            else:\n",
    "                y_pred_orig = y_pred\n",
    "\n",
    "            y_pred_orig = np.reshape(y_pred_orig, (1, 3))\n",
    "\n",
    "            if bag_of_hits == BagOfHits.All:\n",
    "                hits = bag_of_hits_all\n",
    "            elif bag_of_hits == BagOfHits.Track:\n",
    "                hits = curr_track\n",
    "            elif bag_of_hits == BagOfHits.Layer:                    \n",
    "                hits = curr_layer\n",
    "            \n",
    "            if cylindrical:\n",
    "                rho, eta, phi = y_pred_orig[0][0], y_pred_orig[0][1], y_pred_orig[0][2]\n",
    "                #print(rho,eta,phi)\n",
    "                x, y, z = convert_rhoetaphi_to_xyz(rho, eta, phi)\n",
    "                #print(x,y,z)\n",
    "                y_pred_orig[0][0] = x\n",
    "                y_pred_orig[0][1] = y\n",
    "                y_pred_orig[0][2] = z\n",
    "                \n",
    "                #print(y_pred_orig)\n",
    "                    \n",
    "            dist = distance.cdist(hits, y_pred_orig, 'euclidean')\n",
    "            idx = np.argmin(dist)\n",
    "            near_pred = hits[idx]\n",
    "\n",
    "            # if curr_hit is in cartesian coord, near_pred must be in cartesian coord too\n",
    "            if np.isclose(curr_hit, near_pred, atol=tol).all():\n",
    "                count_correct[i]+=1\n",
    "                #print('count_correct[%s] = %s ' % (i, count_correct[i]))\n",
    "                \n",
    "            if verbose:\n",
    "                print('pred:', y_pred)\n",
    "                print('inv pred:', y_pred_orig)\n",
    "                print('current:', curr_hit)\n",
    "                print('nearest:', near_pred)\n",
    "            \n",
    "            if cylindrical:\n",
    "                x, y, z = near_pred[0], near_pred[1], near_pred[2]\n",
    "                #print(x,y,z)\n",
    "                rho, eta, phi = convert_xyz_to_rhoetaphi(x, y, z)\n",
    "                #print(rho,eta,phi)\n",
    "                near_pred[0] = rho\n",
    "                near_pred[1] = eta\n",
    "                near_pred[2] = phi\n",
    "                \n",
    "            #curr_track = np.delete(curr_track, idx, 0)\n",
    "            #near_pred_orig, idx = model.nearest_hit(y_pred_orig, bag_of_hits, silent=True)\n",
    "            \n",
    "           \n",
    "            \n",
    "            '''            \n",
    "            d1 = calculate_distances_vec(curr_hit, y_pred_orig[0])\n",
    "            d2 = calculate_distances_vec(curr_hit, near_pred)\n",
    "            #print('d1 %s, d2 %s' % (d1, d2))\n",
    "            \n",
    "            if d1 <= d2:\n",
    "                # original coordinates\n",
    "                if np.isclose(curr_hit, y_pred_orig, atol=0.09).all():    \n",
    "                    count_correct[i]=+1\n",
    "                #print('d1')    \n",
    "                predicted.append(y_pred)\n",
    "                predicted_orig.append(y_pred_orig)\n",
    "            else:\n",
    "                # original coordinates\n",
    "                if np.isclose(curr_hit, near_pred_orig, atol=0.09).all():    \n",
    "                    count_correct[i]=+1\n",
    "                #print('d2')                                         \n",
    "                near_pred_scaled = data.y_scaler.transform(np.reshape(near_pred, (1, 3)))\n",
    "                print('near scaled:', near_pred_scaled)\n",
    "                predicted.append(near_pred_scaled)\n",
    "                predicted_orig.append(near_pred)\n",
    "            '''\n",
    "            \n",
    "            '''\n",
    "            near_pred = np.reshape(near_pred, (1, 3))\n",
    "            if normalise:\n",
    "                near_pred = data.y_scaler.transform(near_pred)\n",
    "            else:\n",
    "                near_pred = near_pred\n",
    "            \n",
    "            if verbose:\n",
    "                print('near scaled:', near_pred)\n",
    "            '''   \n",
    "            \n",
    " \n",
    "                    \n",
    "            #near adiciona em valores originaeis\n",
    "            predicted.append(near_pred)\n",
    "            \n",
    "            #predicted_orig.append(near_pred_orig)\n",
    "            #print('-----\\n')\n",
    "            \n",
    "            curr_frame = curr_frame_orig[1:]\n",
    "            curr_frame = np.insert(curr_frame, [3], predicted[-1], axis=0)\n",
    "            \n",
    "            #curr_frame_new = data.x_scaler.transform(np.reshape(curr_frame_inv, (1, 12)))\n",
    "            #curr_frame_new_inv = data.inverse_transform_x(pd.DataFrame(curr_frame).values.flatten())\n",
    "            \n",
    "            #print('new frame ', curr_frame_new.reshape(4,3))\n",
    "            #print('new frame inv ', curr_frame_new_inv.reshape(4,3))\n",
    "            \n",
    "        pred_sequences.append(predicted)\n",
    "        #pred_sequences_orig.append(predicted_orig)\n",
    "        \n",
    "        if verbose:\n",
    "            if j == 3: break\n",
    "                \n",
    "    print('[Model] Prediction Finished.')\n",
    "    timer.stop()\n",
    "\n",
    "    return pred_sequences, count_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = X_test.iloc[0:1000,]\n",
    "#y_test = y_test[0:1000]\n",
    "X_test_ = data.reshape3d(X_test, time_steps, num_features)\n",
    "y_test_ = data.reshape3d(y_test, 6, num_features)\n",
    "\n",
    "print(X_test_.shape)\n",
    "print(y_test_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pred_full_res, correct = predict_full_sequences_nearest1(X_test_, y_test, 6)\n",
    "#print('finished prediction nearest...')\n",
    "\n",
    "#predicted_nearest = convert_vector_to_matrix(pred_full_res, 3, 6)\n",
    "#predicted_nearest = to_frame(predicted_nearest)\n",
    "#predicted_nearest.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux data\n",
    "data_tmp = Dataset(path, split_data, False, num_hits, KindNormalization.Zscore)\n",
    "X_test_aux, y_test_aux = data_tmp.get_testing_data(n_hit_in=time_steps, n_hit_out=1,\n",
    "                                 n_features=num_features, normalise=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_aux = X_test_aux.iloc[0:1000,]\n",
    "y_test_aux = y_test_aux[0:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalise = configs['data']['normalise'] \n",
    "# normalise = True say input data must be scaled or not. If training was normalised we must use the same.\n",
    "pred_full_res, correct = model.predict_full_sequences_nearest2(X_test_, y_test, data, BagOfHits.Layer, y_test_aux=None, 6, \n",
    "                                                         normalise=normalise, cylindrical=cylindrical,\n",
    "                                                         verbose=False, tol=0.01)\n",
    "\n",
    "    \n",
    "predicted_nearest = convert_vector_to_matrix(pred_full_res, 3, 6)\n",
    "predicted_nearest = to_frame(predicted_nearest)\n",
    "predicted_nearest.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = num_hits - time_steps\n",
    "correct = [0]\n",
    "y_pred = None\n",
    "if cylindrical:\n",
    "    \n",
    "    if type_pred == \"normal\":\n",
    "        y_pred = model.predict_full_sequences(X_test_, data, num_hits=6, normalise=True)\n",
    "    elif type_pred == \"nearest\":                 \n",
    "        # get data in coord cartesian\n",
    "        data_tmp = Dataset(data_file, split_data, False, num_hits, KindNormalization.Zscore)\n",
    "\n",
    "        X_test_aux, y_test_aux = data_tmp.get_testing_data(n_hit_in=time_steps, n_hit_out=1,\n",
    "                                         n_features=num_features, normalise=False)        \n",
    "        y_pred, correct = model.predict_full_sequences_nearest(X_test_, y_test, data, BagOfHits.Layer, y_test_aux, seq_len, \n",
    "                                                             normalise=True, cylindrical=cylindrical,\n",
    "                                                             verbose=False)\n",
    "\n",
    "else:\n",
    "    if type_pred == \"normal\":\n",
    "        y_pred = model.predict_full_sequences(X_test_, data, num_hits=6, normalise=True)\n",
    "    elif type_pred == \"nearest\": \n",
    "        y_pred, correct = model.predict_full_sequences_nearest(X_test_, y_test, data, BagOfHits.Layer, None, seq_len, \n",
    "                                                         normalise=True, cylindrical=False,\n",
    "                                                         verbose=False, tol=tolerance)\n",
    "    else:\n",
    "        print('no algorithm defined to predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_nearest = convert_vector_to_matrix(y_pred, 3, 6)\n",
    "predicted_nearest = to_frame(predicted_nearest)\n",
    "predicted_nearest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# vetor de contagens\n",
    "total = X_test.shape[0]\n",
    "print(correct)\n",
    "#taxa_acertos = [(correct*100)/total for x in range(0, len(correct))]\n",
    "print((correct*100)/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#plt.bar(range(1,6), correct)\n",
    "layers = ['layer 5', 'layer 6','layer 7','layer 8','layer 9','layer 10']\n",
    "\n",
    "#plt.bar(np.arange(1, 6, 1), correct)\n",
    "plt.bar(layers, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "current_track = np.array([[236.97, -107.74, -3.],\n",
    "                 [332.56, -140.7, -6.6],\n",
    "                 [468.9,  -177.86,  -10.2],\n",
    "                 [630.02, -208.33,  -15.],\n",
    "                 [791.81, -224.49,  -16.2],\n",
    "                 [997.68,-224.02,  -27.]])\n",
    "'''\n",
    "\n",
    "tracks = np.array([\n",
    " [ 332.56201172, -140.69500732,   -6.5999999 ],\n",
    " [ 468.89599609, -177.86099243,  -10.19999981],\n",
    " [ 630.02398682, -208.33099365,  -15.        ],\n",
    " [ 791.80603027, -224.48699951,  -16.20000076],\n",
    " [ 997.67901611, -224.02400208,  -27.        ]])\n",
    "\n",
    "current = [[236.97200012, -107.73600006, -3. ]]\n",
    "pred = [[239.28717, -102.406906, -5.2484846]]\n",
    "pred = [[ 245.10965, -117.84069,   -6.3022523]]\n",
    "n = model.nearest_hit(pred, tracks, silent=False)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "near = np.array([[332.56, -140.7, -6.6 ]])\n",
    "scaled = data.y_scaler.transform(near)\n",
    "print(scaled)\n",
    "orig = data.inverse_transform_y(scaled)\n",
    "print(orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for Normal Prediction ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# metricas geraeis\n",
    "_,_,_,_,result = calc_score(data.reshape2d(y_test, 1),\n",
    "                    data.reshape2d(predicted, 1), report=True)\n",
    "print(result)\n",
    "\n",
    "calc_score_layer(y_test, predicted, n_features=3)\n",
    "\n",
    "mses, rmses, r2s = calc_score_layer_axes(y_test, predicted)\n",
    "summarize_scores_axes(mses, rmses, r2s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for  Nearest Prediction ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metricas para nearest\n",
    "_,_,_,_,result = calc_score(data.reshape2d(y_test, 1),\n",
    "                    data.reshape2d(predicted_nearest, 1), report=True)\n",
    "print(result)\n",
    "\n",
    "calc_score_layer(y_test, predicted_nearest, n_features=3)\n",
    "\n",
    "mses, rmses, r2s = calc_score_layer_axes(y_test, predicted_nearest)\n",
    "summarize_scores_axes(mses, rmses, r2s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Millimeters ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_mat(scaler, data, n_features=3):\n",
    "    '''\n",
    "        Covert a matrix to scaled values by colum hit \n",
    "    '''\n",
    "    rows = data.shape[0]\n",
    "    cols = data.shape[1]\n",
    "    \n",
    "    begin = 0\n",
    "    for i in range(0, cols, n_features):\n",
    "        end = i + n_features\n",
    "        hit_col = data.iloc[0:,begin:end]\n",
    "        begin = end\n",
    "        scaled = scaler.transform(hit_col)\n",
    "        print(scaled)\n",
    "\n",
    "inverse_transform_mat(data.y_scaler, predicted_nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise = False     \n",
    "if normalise:\n",
    "    print('[Data] Inverse Transforming ...')\n",
    "    y_test_orig = data.inverse_transform_test_y(y_test)\n",
    "    y_predicted_orig = data.inverse_transform_test_y(predicted)\n",
    "    y_predicted_orig_nearest = data.inverse_transform_y(predicted_nearest)\n",
    "    \n",
    "    y_test_orig = pd.DataFrame(y_test_orig)    \n",
    "    y_predicted_orig = pd.DataFrame(y_predicted_orig)    \n",
    "else:\n",
    "    y_test_orig = y_test\n",
    "    y_predicted_orig = predicted\n",
    "    \n",
    "    y_predicted_orig_nearest = predicted_nearest\n",
    "    y_predicted_orig_nearest = pd.DataFrame(y_predicted_orig_nearest)\n",
    "\n",
    "print('[Data] shape y_predicted_orig ', y_predicted_orig.shape)    \n",
    "print('[Data] shape y_test_orig ', y_test_orig.shape)\n",
    "\n",
    "result = calc_score(data.reshape2d(y_test_orig, 1),\n",
    "                    data.reshape2d(y_predicted_orig_nearest, 1), report=False)\n",
    "print(result)\n",
    "r2, rmse, rmses = evaluate_forecast_seq(y_test_orig, y_predicted_orig_nearest)\n",
    "summarize_scores(r2, rmse, rmses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for Visualization ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true, y_true = data.get_testing_data(n_hit_in=time_steps, n_hit_out=1,\n",
    "                                 n_features=num_features, normalise=False)\n",
    "x_true = x_true.iloc[0:1000,]\n",
    "y_true = y_true[0:1000]\n",
    "\n",
    "#x_true = X_test\n",
    "#y_true = y_test\n",
    "print(x_true.shape)\n",
    "print(y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join both dataset must be equal to X_test\n",
    "data_true = np.concatenate([x_true , y_true], axis = 1)\n",
    "data_true = pd.DataFrame(data_true)\n",
    "data_true.columns.name = 'real' \n",
    "\n",
    "print('Shape ', data_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be equal\n",
    "#data_test.values == X_test_new.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join both dataset should be equal to X_test but not equal\n",
    "data_pred = np.concatenate([x_true , y_predicted_orig], axis = 1 )\n",
    "data_pred = pd.DataFrame(data_pred)\n",
    "data_pred.columns.name = 'predito'\n",
    "\n",
    "print('Shape ', data_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join both dataset should be equal to X_test but not equal\n",
    "data_pred_nearest = np.concatenate([x_true , y_predicted_orig_nearest], axis = 1 )\n",
    "data_pred_nearest = pd.DataFrame(data_pred_nearest)\n",
    "\n",
    "data_pred_nearest.columns.name = 'nearest'\n",
    "\n",
    "print('Shape ', data_pred_nearest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should not be equal\n",
    "#data_pred.values == X_test_new.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cylindrical:\n",
    "\n",
    "    y_test_orig.to_csv(os.path.join(output_path, 'y_true_%s_cylin_nearest.csv' % configs['model']['name']),\n",
    "                header=False, index=False)\n",
    "\n",
    "    y_predicted_orig.to_csv(os.path.join(output_path, 'y_pred_%s_cylin_nearest.csv' % configs['model']['name']),\n",
    "                header=False, index=False)\n",
    "\n",
    "    x_true.to_csv(os.path.join(output_path, 'x_true_%s_cylin_nearest.csv' % configs['model']['name']),\n",
    "                header=False, index=False)\n",
    "else:\n",
    "    \n",
    "    y_test_orig.to_csv(os.path.join(output_path, 'y_true_%s_xyz_nearest.csv' % configs['model']['name']),\n",
    "                header=False, index=False)\n",
    "    y_predicted_orig.to_csv(os.path.join(output_path, 'y_pred_%s_xyz_nearest.csv' % configs['model']['name']),\n",
    "                header=False, index=False)\n",
    "\n",
    "    x_true.to_csv(os.path.join(output_path, 'x_true_%s_xyz_nearest.csv' % configs['model']['name']),\n",
    "                header=False, index=False)\n",
    "\n",
    "print('[Output] Results saved at %', output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados originais\n",
    "N_tracks = 50\n",
    "path_html = ''\n",
    "name = configs['model']['name']\n",
    "\n",
    "if cylindrical:\n",
    "    path_html=os.path.join(output_path, 'track-original-%s_cylin_nearest.html' % name)\n",
    "else:\n",
    "    path_html=os.path.join(output_path, 'track-original-%s_xyz_nearest.html' % name)\n",
    "    \n",
    "fig = track_plot_xyz([data_true], n_hits = 10, cylindrical = cylindrical, n_tracks = 50, \n",
    "               path=path_html, title='Track Original #10 Hit - Model %s' % name.upper())\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted data\n",
    "N_tracks = 8\n",
    "path_html = ''\n",
    "name = configs['model']['name']\n",
    "\n",
    "if cylindrical:\n",
    "    path_html=os.path.join(output_path, 'track-predicted-%s_cylin_normal-pred.html' % name)\n",
    "else:\n",
    "    path_html=os.path.join(output_path, 'track-predicted-%s_xyz_normal-pred.html' % name)\n",
    "    \n",
    "fig = track_plot_xyz([data_true, data_pred], n_hits = 10, cylindrical = cylindrical, n_tracks = N_tracks, \n",
    "               path=path_html, title='Track Prediction #10 Hit - Model %s (Nearest hits)' % name.upper(), auto_open=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted data\n",
    "N_tracks = 8\n",
    "path_html = ''\n",
    "name = configs['model']['name']\n",
    "\n",
    "if cylindrical:\n",
    "    path_html=os.path.join(output_path, 'track-predicted-%s_cylin_nearest.html' % name)\n",
    "else:\n",
    "    path_html=os.path.join(output_path, 'track-predicted-%s_xyz_nearest.html' % name)\n",
    "\n",
    "\n",
    "fig = track_plot_xyz([data_true, data_pred_nearest], n_hits = 10, cylindrical = cylindrical, n_tracks = N_tracks, \n",
    "               path=path_html, title='Track Prediction #10 Hit - Model %s (Nearest hits)' % name.upper(), auto_open=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted data\n",
    "N_tracks = 8\n",
    "path_html = ''\n",
    "name = configs['model']['name']\n",
    "\n",
    "if cylindrical:\n",
    "    path_html=os.path.join(output_path, 'track-predicted-%s_cylin_nearest.html' % name)\n",
    "else:\n",
    "    path_html=os.path.join(output_path, 'track-predicted-%s_xyz_nearest.html' % name)\n",
    "\n",
    "\n",
    "fig = track_plot_xyz([data_true, data_pred, data_pred_nearest], n_hits = 10, cylindrical = cylindrical, n_tracks = N_tracks, \n",
    "               path=path_html, title='Track Prediction #10 Hit - Model %s (Nearest hits)' % name.upper(), auto_open=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
